{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Library Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sqlite3\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check & Query\n",
    "filename = 'C:/Users/DELL/Desktop/Course_Recommendation/BEProject/SystemCode/instance/mydb.db'\n",
    "table_name = 'course'\n",
    "sqlite_conn = sqlite3.connect(filename)\n",
    "\n",
    "# Query Table\n",
    "rawdata = pd.read_sql('SELECT * FROM ' + table_name, sqlite_conn, index_col='courseID')\n",
    "\n",
    "sqlite_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for recommendation module\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1) Text Preprocessing\n",
    "# Initilization\n",
    "stopwordsdic = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Takes any rawtext as input and apply text preprocessing:\n",
    "#   - remove all non-ASCII characters\n",
    "#   - lower-casing all text and remove unecessary spaces\n",
    "#   - remove punctuations\n",
    "#   - remove stopwords\n",
    "#   - lemmatize words\n",
    "#   - create bag-of-words (bow) strings\n",
    "def text_preprocess(rawtext):\n",
    "    text = re.sub('([^\\x00-\\x7F])+', '', rawtext)  # Remove all non ASCII characters\n",
    "    text = text.lower()  # lower casing all words\n",
    "    text = text.strip()  # Remove White Spaces\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)  # Remove Punctuations\n",
    "    text = word_tokenize(text)  # Tokenize\n",
    "    text = [word for word in text if word not in stopwordsdic]  # Remove stopwords\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]  # Lemmatize words\n",
    "    bow = ' '.join(text)  # Create Bag-of-Words\n",
    "    return bow\n",
    "\n",
    "\n",
    "# 2) Encoding User Input Features:\n",
    "# Takes list of categorical data (course difficulty, course duration and course free option) as input\n",
    "# Returns one-hot encoded features.\n",
    "def categorical_encode(categorical_input):\n",
    "    encode = np.zeros((1, 6))\n",
    "    # Binary Encode Course Duration (0 - No Preference, 1 - Short, 2 - Medium, 3 - Long)\n",
    "    if categorical_input[0] > 0:\n",
    "        encode[0, categorical_input[0] - 1] = 1\n",
    "    # Binary Encode Course Difficulty (0 - No Preference, 1 - Introductory, 2 - Intermediate, 3 - Advanced)\n",
    "    if categorical_input[1] > 0:\n",
    "        encode[0, categorical_input[1] + 2] = 1\n",
    "        \n",
    "    return encode\n",
    "\n",
    "\n",
    "# 3) TfIdf Vectorizer:\n",
    "# Takes list of tokens as input and apply TfIdf Vectorization based on the pretrained dictionary.\n",
    "def tfidf_vectorize(text, vectorizer):\n",
    "    # Load Tfidf Vectorizer\n",
    "    # vectorizer_file = open(config.tfidf_vectorizer_filepath, 'rb')\n",
    "    # vectorizer = pickle.load(vectorizer_file)\n",
    "    # vectorizer_file.close()\n",
    "    tfidf = vectorizer.transform([text])\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "# 4) Cosine Similarity:\n",
    "# Takes 2 vectors and calculate cosine similarity\n",
    "def cond_sim(input_vec, data_vec):\n",
    "    input_durr = input_vec[:, :3]\n",
    "    input_diff = input_vec[:, 3:]\n",
    "    data_durr = data_vec[:, :3]\n",
    "    data_diff = data_vec[:, 3:6]\n",
    "    # print(str(input_durr)+ \" diff \"+str(input_diff)+\" data dur\"+str(data_durr)+\" \"+str(data_diff))\n",
    "    # print('inp vect '+ str(input_vec)+ 'len '+str((input_vec.shape)))\n",
    "    # print('data vect '+ str(data_vec)+ 'len '+str((data_vec.shape)))\n",
    "    if (input_diff.sum() + input_durr.sum()) == 0:\n",
    "        sim = np.ones(data_vec.shape[0])\n",
    "    elif input_durr.sum() == 0:\n",
    "        sim = cosine_similarity(input_diff, data_diff)\n",
    "    elif input_diff.sum() == 0:\n",
    "        sim = cosine_similarity(input_durr, data_durr)\n",
    "    else:\n",
    "        data_vec=data_vec[:,:6]\n",
    "        sim = cosine_similarity(input_vec, data_vec)\n",
    "  \n",
    "    return sim\n",
    "\n",
    "\n",
    "# 5) Ranking based on popularity index\n",
    "# Given a sorted and threshold filtered ID of recommendations\n",
    "# Batch rank for every batch_size of ID by rating.\n",
    "def ranking(mask, text_sim, categorical_sim, rating):\n",
    "    target_idx = np.arange(text_sim.shape[0])[mask]\n",
    "    target_text_sim = text_sim[mask]\n",
    "    target_categorical_sim = categorical_sim[mask]\n",
    "    target_rating = rating[mask]\n",
    "    target_scores = sorted(np.unique(target_categorical_sim), reverse=True)\n",
    "    rec_idx = np.array([], dtype=int)\n",
    "    rec_sim = np.array([])\n",
    "    for score in target_scores:\n",
    "        group_mask = (target_categorical_sim == score)\n",
    "        group_idx = target_idx[group_mask]\n",
    "        group_text_sim = target_text_sim[group_mask]\n",
    "        group_rating = target_rating[group_mask]\n",
    "        group_sort_idx = np.argsort(group_rating)[::-1]\n",
    "        rec_idx = np.append(rec_idx, group_idx[group_sort_idx])\n",
    "        rec_sim = np.append(rec_sim, group_text_sim[group_sort_idx])\n",
    "    return rec_sim, rec_idx\n",
    "\n",
    "\n",
    "# 6) Load-up Pickle Object Data Files\n",
    "def load_pickle(filename):\n",
    "    data_file = open(filename, 'rb')\n",
    "    data = pickle.load(data_file)\n",
    "    data_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recommendation module\n",
    "# Takes user input and returns a sorted list of recommended courses.\n",
    "\n",
    "# Initialize Library Setup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recommend Function\n",
    "def recommend(user_input, rating_data, tfidf_vectorizer, tfidf_data, categorical_data):\n",
    "    # 1. Feature Extraction - Text Based (TfIdf)\n",
    "    # Load Tfidf Data Sparse Matrix\n",
    "    # tfidf_data_file = open(config.tfidf_data_filepath, 'rb')\n",
    "    # tfidf_data = pickle.load(tfidf_data_file)\n",
    "    # tfidf_data_file.close()\n",
    "    # Text Input and Similarity Score\n",
    "    text_input = user_input[0]\n",
    "    #print('text input:  ',text_input)\n",
    "    text_processed = text_preprocess(text_input)\n",
    "    tfidf_vect = tfidf_vectorize(text_processed, tfidf_vectorizer)\n",
    "    tfidf_sim = cosine_similarity(tfidf_vect, tfidf_data).ravel()\n",
    "    \n",
    "  \n",
    "   \n",
    "    # 2. Feature Extraction - Categorical Based (One-Hot Encoded)\n",
    "    # Load Categorical One-Hot Encoded Sparse Matrix\n",
    "\n",
    "    # categorical_data_file = open(config.categorical_data_filepath, 'rb')\n",
    "    # categorical_data = pickle.load(categorical_data_file)\n",
    "    # categorical_data_file.close()\n",
    "    # Categroical Input and Similarity Score\n",
    "    categorical_input = user_input[1:3]\n",
    "    #print('cipt: ',categorical_input)\n",
    "    \n",
    "    categorical_vect =categorical_encode(categorical_input)\n",
    "\n",
    "    categorical_sim = cond_sim(categorical_vect, categorical_data[:, :-1]).ravel()\n",
    "\n",
    "    # 3. Recommendation Masks (Free vs Paid Courses Masks)\n",
    "    free_option_ind = user_input[-1]\n",
    "    free_option_data = categorical_data[:, -1]\n",
    "    thres_mask = (tfidf_sim > text_thres)\n",
    "    if free_option_ind == 1:\n",
    "        free_mask = ((free_option_data == 1) * thres_mask) == 1\n",
    "    else:\n",
    "        free_mask = (np.ones(tfidf_data.shape[0]) * thres_mask) == 1\n",
    "    paid_mask = ((np.ones(tfidf_data.shape[0]) * thres_mask) - free_mask) == 1\n",
    "\n",
    "    # 4. Apply Masks and Rank by categorical_sim group and rating\n",
    "    rec_sim, rec_idx = ranking(free_mask, tfidf_sim, categorical_sim, rating_data)\n",
    "\n",
    "    # 5. Append paid courses if number of free courses below a threshold\n",
    "    if (free_mask.sum() < free_show_thres) and (paid_mask.sum() > 0):\n",
    "        paid_sim, paid_idx = ranking(paid_mask, tfidf_sim, categorical_sim, rating_data)\n",
    "        rec_sim = np.append(rec_sim, paid_sim)\n",
    "        rec_idx = np.append(rec_idx, paid_idx)\n",
    "     \n",
    "    # 6. Convert Index to courseID\n",
    "    rec_idx = rec_idx + 1\n",
    "    course_sim = rec_sim[:recommend_topn].tolist()\n",
    "    course_idx = rec_idx[:recommend_topn].tolist()\n",
    "\n",
    "    return course_idx\n",
    "\n",
    "\n",
    "def recommend_default(rating_data):\n",
    "    sort_idx = (np.argsort(rating_data)[::-1])\n",
    "    sort_course = sort_idx[:recommend_default_topn]\n",
    "    default_course = [int(x+1) for x in sort_course]\n",
    "    return default_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONFIGURATION FOR RECOMMENDER MODULE\n",
    "# DATA FILE PATH\n",
    "tfidf_data_filepath = ('Feature Map/tfidf_data.pickle')\n",
    "categorical_data_filepath = 'Feature Map/categorical_data.pickle'\n",
    "tfidf_vectorizer_filepath = 'Feature Map/tfidf_vectorizer.pickle'\n",
    "# TEXT BASED RECOMMENDATION THRESHOLD\n",
    "text_thres = 0.5\n",
    "# MINIMUM FREE COURSE COUNT THRESHOLD\n",
    "free_show_thres = 2\n",
    "# RECOMMENDATION RESULTS SIZE\n",
    "recommend_topn = 3\n",
    "# DEFAULT POPULAR RESULTS SIZE\n",
    "recommend_default_topn = 3\n",
    "#multiplier=5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structures - Full Course Using C and C++\n",
      "Learning Data Structures and Algorithms\n",
      "Algorithms and Data Structures in Javascript (2020)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ainput = ['data structures', 1, 0, 1]\n",
    "rawdata_rating = rawdata['popularity_index']\n",
    "a=load_pickle(tfidf_data_filepath)\n",
    "b=load_pickle(categorical_data_filepath)\n",
    "c=load_pickle(tfidf_vectorizer_filepath)\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning using Python Programming\n",
      "Machine Learning Course for Beginners\n",
      "Machine Learning for Business\n"
     ]
    }
   ],
   "source": [
    "ainput = ['machine learning', 1, 0, 1]  # what to learn, difficulty,duration.free\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to Web Design and Development\n",
      "Introduction to Web Design and Development\n",
      "Modern Web Development From Zero To Advanced\n"
     ]
    }
   ],
   "source": [
    "ainput = ['web development', 0, 1, 1]  # what to learn, difficulty,duration.free\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Data Science\n",
      "Zero to Agile Data Science\n",
      "Introduction To Data Science\n"
     ]
    }
   ],
   "source": [
    "ainput = ['data science', 0, 2, 1]  # what to learn, duration,difficulty,.free\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern Web Development From Zero To Advanced\n",
      "Learn Professional Web Development Skills From Scratch -2021\n",
      "Full Front-End Web Development Course\n"
     ]
    }
   ],
   "source": [
    "ainput = ['web development', 2, 1, 0]  # what to learn, difficulty,duration.free\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL: Cloud Computing / CompTIA Cloud+ Cert. (CV0-002)\n",
      "Certified Cloud Security Officer (CCSO)\n",
      "Learning Path: Microsoft Azure: Cloud Computing and Storage\n"
     ]
    }
   ],
   "source": [
    "ainput = ['cloud computing', 2, 3, 0]  # what to learn, difficulty,duration.free\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create similarity matrix\n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "# job_roles=pd.read_csv('data preprocess\\preprocessed data\\job_skills.csv')\n",
    "# job_tfidf_matrix = tfidf.transform(job_roles[\"skill_set\"])\n",
    "# load_pickle(tfidf_data_filepath)\n",
    "# similarity_matrix = cosine_similarity(job_tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# # recommend courses for each job role\n",
    "# for i, job in enumerate(job_roles[\"role\"]):\n",
    "#     similar_courses_indices = similarity_matrix[i].argsort()[::-1][:5] # get top 5 most similar courses\n",
    "#     similar_courses = courses.iloc[similar_courses_indices][[\"title\", \"provider\", \"keywords\"]].reset_index(drop=True)\n",
    "#     print(f\"Recommended courses for {job}:\")\n",
    "#     print(similar_courses)\n",
    "#     print()\n",
    "\n",
    "# ainput = ['cloud computing', 2, 3, 0]  # what to learn, difficulty,duration.free\n",
    "# idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "\n",
    "# for i in idx:\n",
    "#     print(rawdata['title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_role', 'skill_set']\n",
      "['Data Analyst', 'Statistical analysis,ANOVA,MySQL,SQL,Problem solving,Oracle,Regression analysis,Data manipulation,R,Seaborn,Azure,Power BI,SciPy,Matplotlib,Tableau,PostgreSQL,Hypothesis testing,AWS,Machine learning,Pandas,Data analysis,Data cleaning,Google Analytics,NumPy,SQL Server,Communication skills,Data visualization,Critical thinking,Statistics,Excel,Time series analysis,MongoDB,QlikView,Python,Looker']\n",
      "['Data Scientist', 'Statistical analysis,Hadoop,SQL,Deep learning,Problem solving,TensorFlow,NLP,R,Azure,Experimentation,Model tuning,Statistical modeling,Scikit-learn,Data wrangling,Machine learning,AWS,Big data,Data analysis,Reinforcement learning,PyTorch,Communication skills,Data visualization,Keras,Spark,Python']\n",
      "['Software Developer', 'API development,Docker,Windows,Kubernetes,MySQL,SQL,Web development,Problem solving,Git,Oracle,DevOps,Agile,macOS,Data structures,PHP,C#,Flask,JavaScript,React,C++,Mobile app development,Programming,Testing,Spring,Linux,Cloud computing,Angular,Ruby on Rails,Debugging,PostgreSQL,Unit testing,Kotlin,Swift,Objective-C,SQL Server,Unity,Ruby,.NET,Object-oriented programming (OOP),Node.js,MongoDB,Java,Django,Python,Algorithms']\n",
      "['Full Stack Developer', 'Semantic UI,API development,MySQL,Git,Oracle,Agile,Ionic,Express,Vue.js,PHP,Python,JavaScript,REST APIs,React,Database management,CSS,Materialize,Front-end development,HTML,Angular,Ruby on Rails,PostgreSQL,Bootstrap,React Redux,SQL Server,Back-end development,ASP.NET,Node.js,jQuery,Agile methodologies,Vue.js Vuex,MongoDB,Express.js,React Native,Electron,Django,Flask']\n",
      "['Web Developer', 'SQL,Responsive design,Git,Agile,Vue.js,PHP,JavaScript,React,REST APIs,CSS,HTML,Angular,Bootstrap,Web performance optimization,SEO,UI/UX design,Node.js,jQuery,Python']\n",
      "['Cloud Solutions Architect', 'Data migration,Google Cloud Platform,Networking,Docker,AWS,Terraform,Kubernetes,Azure,Security,Architecture design,Cloud computing']\n",
      "['Cybersecurity Analyst', 'Penetration testing,Firewall management,Firewalls,Nmap,Intrusion detection,Security analysis,SIEM,Metasploit,Vulnerability scanners,Risk assessment,Antivirus software,IDS/IPS']\n",
      "['Network Administrator', 'Routing protocols,Active Directory,WAN,LAN,VPN,Windows Server,Problem solving,Security,TCP/IP,DHCP,DNS,Linux,Virtualization,Juniper,Firewalls,Cisco']\n",
      "['Network Architect', 'Routing protocols,Active Directory,WAN,LAN,VPN,Windows Server,Problem solving,Security,TCP/IP,DHCP,DNS,Linux,Virtualization,Network design,Juniper,Firewalls,Cisco']\n",
      "['Database Administrator', 'Database backup and recovery,PostgreSQL,MySQL,SQL,Windows Server,Problem solving,Oracle,Database security,MongoDB,Database performance tuning,Linux,Database design,Shell scripting']\n",
      "['DevOps Engineer', 'Docker,Ubuntu,Proxy Servers,Kubernetes,Ansible,LVM,Git,RedHat,EC2,SSL/TLS,Monitoring and logging tools,Prometheus,Automation tools,Azure,Linux,Bash Shell,Cloud computing,Networking,OpenStack,AWS,Amazon S3,Continuous integration/continuous deployment (CI/CD),Grafana,TCP/IP,Fedora,Containerization technologies,Zabbix,Load Balancing,Perl,ELB,Firewalls,Google Cloud Platform,EFS,Ruby,Route 53,Vulnerability Scanning,Terraform,CentOS,Security and compliance,ELK Stack,Auto Scaling,Jenkins,DNS,Java,Scripting languages,Penetration Testing,Python']\n",
      "['Systems Analyst', 'Requirement gathering,Waterfall,Systems analysis,Software development life cycle (SDLC),Agile,Process improvement']\n",
      "['Game Developer', 'Gameplay mechanics,UI/UX design,Game engines and frameworks,3D modeling and animation,Project management,Programming languages,Game design principles,Game physics']\n",
      "['UI/UX Designer', 'User interface design,Color theory,JavaScript,Usability testing,Prototyping,Typography,Information architecture,HTML/CSS,Visual design,Graphic design tools,Wireframing,Interaction design,Wireframing and prototyping tools,User experience design']\n",
      "['IT Manager', 'Project management,IT governance and compliance,Risk management,Budgeting and financial management,IT strategy development,Vendor management']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('job_skills.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_role</th>\n",
       "      <th>skill_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Statistical analysis,ANOVA,MySQL,SQL,Problem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Statistical analysis,Hadoop,SQL,Deep learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>API development,Docker,Windows,Kubernetes,MySQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Semantic UI,API development,MySQL,Git,Oracle,A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>SQL,Responsive design,Git,Agile,Vue.js,PHP,Jav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cloud Solutions Architect</td>\n",
       "      <td>Data migration,Google Cloud Platform,Networkin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cybersecurity Analyst</td>\n",
       "      <td>Penetration testing,Firewall management,Firewa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Network Administrator</td>\n",
       "      <td>Routing protocols,Active Directory,WAN,LAN,VPN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Network Architect</td>\n",
       "      <td>Routing protocols,Active Directory,WAN,LAN,VPN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Database Administrator</td>\n",
       "      <td>Database backup and recovery,PostgreSQL,MySQL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Docker,Ubuntu,Proxy Servers,Kubernetes,Ansible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Requirement gathering,Waterfall,Systems analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Game Developer</td>\n",
       "      <td>Gameplay mechanics,UI/UX design,Game engines a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UI/UX Designer</td>\n",
       "      <td>User interface design,Color theory,JavaScript,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IT Manager</td>\n",
       "      <td>Project management,IT governance and complianc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     job_role  \\\n",
       "0                Data Analyst   \n",
       "1              Data Scientist   \n",
       "2          Software Developer   \n",
       "3        Full Stack Developer   \n",
       "4               Web Developer   \n",
       "5   Cloud Solutions Architect   \n",
       "6       Cybersecurity Analyst   \n",
       "7       Network Administrator   \n",
       "8           Network Architect   \n",
       "9      Database Administrator   \n",
       "10            DevOps Engineer   \n",
       "11            Systems Analyst   \n",
       "12             Game Developer   \n",
       "13             UI/UX Designer   \n",
       "14                 IT Manager   \n",
       "\n",
       "                                            skill_set  \n",
       "0   Statistical analysis,ANOVA,MySQL,SQL,Problem s...  \n",
       "1   Statistical analysis,Hadoop,SQL,Deep learning,...  \n",
       "2   API development,Docker,Windows,Kubernetes,MySQ...  \n",
       "3   Semantic UI,API development,MySQL,Git,Oracle,A...  \n",
       "4   SQL,Responsive design,Git,Agile,Vue.js,PHP,Jav...  \n",
       "5   Data migration,Google Cloud Platform,Networkin...  \n",
       "6   Penetration testing,Firewall management,Firewa...  \n",
       "7   Routing protocols,Active Directory,WAN,LAN,VPN...  \n",
       "8   Routing protocols,Active Directory,WAN,LAN,VPN...  \n",
       "9   Database backup and recovery,PostgreSQL,MySQL,...  \n",
       "10  Docker,Ubuntu,Proxy Servers,Kubernetes,Ansible...  \n",
       "11  Requirement gathering,Waterfall,Systems analys...  \n",
       "12  Gameplay mechanics,UI/UX design,Game engines a...  \n",
       "13  User interface design,Color theory,JavaScript,...  \n",
       "14  Project management,IT governance and complianc...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_roles=pd.read_csv('job_skills.csv')\n",
    "job_roles.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # load job roles dataset\n",
    "# job_roles_df = pd.read_csv(\"job_skills.csv\")\n",
    "\n",
    "# # load courses dataset\n",
    "# courses_df = pd.read_csv(\"courses_with_keywords.csv\")\n",
    "\n",
    "# # create TF-IDF matrix for courses dataset\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "# courses_tfidf = tfidf_vectorizer.fit_transform(courses_df[\"keywords\"])\n",
    "\n",
    "# # create function to recommend courses for a given job role\n",
    "# def recommend_courses(job_role):\n",
    "#     # get skill set for job role\n",
    "#     skill_set = job_roles_df.loc[job_roles_df[\"job_role\"] == job_role, \"skill_set\"].values[0].split(\",\")\n",
    "    \n",
    "#     # create TF-IDF vector for skill set\n",
    "#     skill_set_tfidf = tfidf_vectorizer.transform([\" \".join(skill_set)])\n",
    "    \n",
    "#     # calculate cosine similarities between skill set vector and courses vectors\n",
    "#     similarities = courses_tfidf.dot(skill_set_tfidf.T).toarray().flatten()\n",
    "    \n",
    "#     # sort courses by similarity score and return top 5\n",
    "#     top_indices = similarities.argsort()[::-1][:10]\n",
    "#     return courses_df.loc[top_indices, [\"title\", \"url\", \"categories\", \"description_short\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend_courses(job_role, difficulty=0, duration=0, free=1):\n",
    "#     # get skill set for job role\n",
    "#     skill_set = job_roles_df.loc[job_roles_df[\"job_role\"] == job_role, \"skill_set\"].values[0].split(\",\")\n",
    "    \n",
    "#     # create TF-IDF vector for skill set\n",
    "#     skill_set_tfidf = tfidf_vectorizer.transform([\" \".join(skill_set)])\n",
    "    \n",
    "#     # calculate cosine similarities between skill set vector and courses vectors\n",
    "#     similarities = courses_tfidf.dot(skill_set_tfidf.T).toarray().flatten()\n",
    "    \n",
    "#     # sort courses by similarity score and return top 10\n",
    "#     top_indices = similarities.argsort()[::-1][:5]\n",
    "    \n",
    "#     # filter courses based on difficulty level\n",
    "    \n",
    "    \n",
    "#     return courses_df.loc[top_indices, [\"title\", \"url\", \"categories\", \"description_short\", \"difficulty\", \"duration\", \"free_option\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend_courses(\"Data Analyst\", difficulty=1, free=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for job in job_roles['skill_set']:\n",
    "#     # my_string = job\n",
    "#     # my_list = my_string.split(\",\")\n",
    "\n",
    "   \n",
    "#     # my_string = \" \".join(my_list)\n",
    "#     # print(my_string)\n",
    "#     job=job.split(',')\n",
    "#     for j in job :\n",
    "#         ainput = [j, 0, 0, 0]  # what to learn, difficulty,duration.free\n",
    "        \n",
    "#         idx=recommend(ainput,rawdata_rating,c,a,b)\n",
    "#         for i in idx:\n",
    "#             print(j)\n",
    "#             print(rawdata['title'][i])\n",
    "#             print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recommendation module\n",
    "# Takes user input and returns a sorted list of recommended courses.\n",
    "\n",
    "# Initialize Library Setup\n",
    "\n",
    "job_roles_df=pd.read_csv('job_skills.csv')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "def text_preprocess_jcr(rawtext):\n",
    "    text = ', '.join(rawtext)  # Join list elements with a comma and space\n",
    "    text = re.sub('([^\\x00-\\x7F])+', '', text)  # Remove all non ASCII characters\n",
    "    text = text.lower()  # lower casing all words\n",
    "    text = text.strip()  # Remove White Spaces\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # remove stop words\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])  # lemmatization\n",
    "    return text\n",
    "# Utility functions for recommendation module\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2) Encoding User Input Features:\n",
    "# Takes list of categorical data (course difficulty, course duration and course free option) as input\n",
    "# Returns one-hot encoded features.\n",
    "def categorical_encode(categorical_input):\n",
    "    encode = np.zeros((1, 6))\n",
    "    # Binary Encode Course Duration (0 - No Preference, 1 - Short, 2 - Medium, 3 - Long)\n",
    "    if categorical_input[0] > 0:\n",
    "        encode[0, categorical_input[0] - 1] = 1\n",
    "    # Binary Encode Course Difficulty (0 - No Preference, 1 - Introductory, 2 - Intermediate, 3 - Advanced)\n",
    "    if categorical_input[1] > 0:\n",
    "        encode[0, categorical_input[1] + 2] = 1\n",
    "        \n",
    "    return encode\n",
    "\n",
    "\n",
    "# 3) TfIdf Vectorizer:\n",
    "# Takes list of tokens as input and apply TfIdf Vectorization based on the pretrained dictionary.\n",
    "def tfidf_vectorize(text, vectorizer):\n",
    "    # Load Tfidf Vectorizer\n",
    "    # vectorizer_file = open(config.tfidf_vectorizer_filepath, 'rb')\n",
    "    # vectorizer = pickle.load(vectorizer_file)\n",
    "    # vectorizer_file.close()\n",
    "    tfidf = vectorizer.transform([text])\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "# 4) Cosine Similarity:\n",
    "# Takes 2 vectors and calculate cosine similarity\n",
    "def cond_sim(input_vec, data_vec):\n",
    "    input_durr = input_vec[:, :3]\n",
    "    input_diff = input_vec[:, 3:]\n",
    "    data_durr = data_vec[:, :3]\n",
    "    data_diff = data_vec[:, 3:6]\n",
    "    # print(str(input_durr)+ \" diff \"+str(input_diff)+\" data dur\"+str(data_durr)+\" \"+str(data_diff))\n",
    "    # print('inp vect '+ str(input_vec)+ 'len '+str((input_vec.shape)))\n",
    "    # print('data vect '+ str(data_vec)+ 'len '+str((data_vec.shape)))\n",
    "    if (input_diff.sum() + input_durr.sum()) == 0:\n",
    "        sim = np.ones(data_vec.shape[0])\n",
    "    elif input_durr.sum() == 0:\n",
    "        sim = cosine_similarity(input_diff, data_diff)\n",
    "    elif input_diff.sum() == 0:\n",
    "        sim = cosine_similarity(input_durr, data_durr)\n",
    "    else:\n",
    "        data_vec=data_vec[:,:6]\n",
    "        sim = cosine_similarity(input_vec, data_vec)\n",
    "  \n",
    "    return sim\n",
    "\n",
    "\n",
    "# 5) Ranking based on popularity index\n",
    "# Given a sorted and threshold filtered ID of recommendations\n",
    "# Batch rank for every batch_size of ID by rating.\n",
    "def ranking(mask, text_sim, categorical_sim, rating):\n",
    "    target_idx = np.arange(text_sim.shape[0])[mask]\n",
    "    target_text_sim = text_sim[mask]\n",
    "    target_categorical_sim = categorical_sim[mask]\n",
    "    target_rating = rating[mask]\n",
    "    target_scores = sorted(np.unique(target_categorical_sim), reverse=True)\n",
    "    rec_idx = np.array([], dtype=int)\n",
    "    rec_sim = np.array([])\n",
    "    for score in target_scores:\n",
    "        group_mask = (target_categorical_sim == score)\n",
    "        group_idx = target_idx[group_mask]\n",
    "        group_text_sim = target_text_sim[group_mask]\n",
    "        group_rating = target_rating[group_mask]\n",
    "        group_sort_idx = np.argsort(group_rating)[::-1]\n",
    "        rec_idx = np.append(rec_idx, group_idx[group_sort_idx])\n",
    "        rec_sim = np.append(rec_sim, group_text_sim[group_sort_idx])\n",
    "    return rec_sim, rec_idx\n",
    "\n",
    "\n",
    "# 6) Load-up Pickle Object Data Files\n",
    "def load_pickle(filename):\n",
    "    data_file = open(filename, 'rb')\n",
    "    data = pickle.load(data_file)\n",
    "    data_file.close()\n",
    "    return data\n",
    "# Recommend Function\n",
    "def recommend_job_role_based(user_input, rating_data, tfidf_vectorizer, tfidf_data, categorical_data):\n",
    "    # 1. Feature Extraction - Text Based (TfIdf)\n",
    "    # Load Tfidf Data Sparse Matrix\n",
    "    # tfidf_data_file = open(config.tfidf_data_filepath, 'rb')\n",
    "    # tfidf_data = pickle.load(tfidf_data_file)\n",
    "    # tfidf_data_file.close()\n",
    "    # Text Input and Similarity Score\n",
    "        # get skill set for job role\n",
    "    skill_set = job_roles_df.loc[job_roles_df[\"job_role\"] == user_input[0], \"skill_set\"].values[0].split(\",\")\n",
    "   \n",
    "    print(skill_set)\n",
    "    # create TF-IDF vector for skill set\n",
    "    skill_set_tfidf = tfidf_vectorizer.transform([\" \".join(skill_set)])\n",
    "    \n",
    "    text_input = skill_set\n",
    "    #print('text input:  ',text_input)\n",
    "    text_processed = text_preprocess_jcr(text_input)\n",
    "    tfidf_vect = tfidf_vectorize(text_processed, tfidf_vectorizer)\n",
    "    tfidf_sim = cosine_similarity(tfidf_vect, tfidf_data).ravel()\n",
    "    \n",
    "  \n",
    "   \n",
    "    # 2. Feature Extraction - Categorical Based (One-Hot Encoded)\n",
    "    # Load Categorical One-Hot Encoded Sparse Matrix\n",
    "\n",
    "    # categorical_data_file = open(config.categorical_data_filepath, 'rb')\n",
    "    # categorical_data = pickle.load(categorical_data_file)\n",
    "    # categorical_data_file.close()\n",
    "    # Categroical Input and Similarity Score\n",
    "    categorical_input = user_input[1:3]\n",
    "    #print('cipt: ',categorical_input)\n",
    "    \n",
    "    categorical_vect =categorical_encode(categorical_input)\n",
    "\n",
    "    categorical_sim = cond_sim(categorical_vect, categorical_data[:, :-1]).ravel()\n",
    "\n",
    "    # 3. Recommendation Masks (Free vs Paid Courses Masks)\n",
    "    free_option_ind = user_input[-1]\n",
    "    free_option_data = categorical_data[:, -1]\n",
    "    thres_mask = (tfidf_sim > text_thres)\n",
    "    if free_option_ind == 1:\n",
    "        free_mask = ((free_option_data == 1) * thres_mask) == 1\n",
    "    else:\n",
    "        free_mask = (np.ones(tfidf_data.shape[0]) * thres_mask) == 1\n",
    "    paid_mask = ((np.ones(tfidf_data.shape[0]) * thres_mask) - free_mask) == 1\n",
    "\n",
    "    # 4. Apply Masks and Rank by categorical_sim group and rating\n",
    "    rec_sim, rec_idx = ranking(free_mask, tfidf_sim, categorical_sim, rating_data)\n",
    "\n",
    "    # 5. Append paid courses if number of free courses below a threshold\n",
    "    if (free_mask.sum() < free_show_thres) and (paid_mask.sum() > 0):\n",
    "        paid_sim, paid_idx = ranking(paid_mask, tfidf_sim, categorical_sim, rating_data)\n",
    "        rec_sim = np.append(rec_sim, paid_sim)\n",
    "        rec_idx = np.append(rec_idx, paid_idx)\n",
    "     \n",
    "    # 6. Convert Index to courseID\n",
    "    rec_idx = rec_idx + 1\n",
    "    course_sim = rec_sim[:recommend_topn].tolist()\n",
    "    course_idx = rec_idx[:recommend_topn].tolist()\n",
    "\n",
    "    return course_idx\n",
    "\n",
    "\n",
    "def recommend_default(rating_data):\n",
    "    sort_idx = (np.argsort(rating_data)[::-1])\n",
    "    sort_course = sort_idx[:recommend_default_topn]\n",
    "    default_course = [int(x+1) for x in sort_course]\n",
    "    return default_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Routing protocols', 'Active Directory', 'WAN', 'LAN', 'VPN', 'Windows Server', 'Problem solving', 'Security', 'TCP/IP', 'DHCP', 'DNS', 'Linux', 'Virtualization', 'Network design', 'Juniper', 'Firewalls', 'Cisco']\n",
      "100\n",
      "Azure Active Directory Identity and Access Management Course\n",
      "CompTIA Network+ (N10-007) Cert Prep: 5 Securing TCP/IP\n",
      "Basics of BIND DNS Server\n",
      "Course 3: MCSA Windows Server 2019 Active Directory\n",
      "Planning for Azure Active Directory\n",
      "Networking Foundations: Local Area Networks (LANs)\n",
      "Mastering Modbus TCP/IP Network Communication\n",
      "Windows Server 2012 R2: Configure Identity and Access Solutions\n",
      "Windows Server 2019: Install and Configure Active Directory\n",
      "Windows 7: Networking and Security\n",
      "Cisco Network Security: VPN\n",
      "Active Directory & Group Policy Lab 2019\n",
      "Windows Server 2016 - Practical Guide for Beginners\n",
      "Networking Foundations: IP Addressing\n",
      "Linux Administration: Build 5 Hands-On Linux Projects\n",
      "Linux: Linux Security Masterclass: 3-in-1\n",
      "Extending On-Prem Active Directory into Microsoft Azure\n",
      "The World of Computer Networking. Your CCNA starts here\n",
      "Build an Active Directory Lab in Microsoft Azure in 1 Hour\n",
      "Juniper JNCIA-Junos JN0-103 with Ben Jacobson\n",
      "Master Class : TCP/IP Mechanics from Scratch to Expert\n",
      "MPLS Layer 3 VPN\n",
      "Azure Active Directory: Basics\n",
      "Secure your Home Network with a Raspberry Pi and Python\n",
      "MTA: Windows Server 2016 Administration Fundamentals: 98-365\n",
      "Make a Your Own Free VPN with AWS/Cloud Computing!\n",
      "Active Directory: Everything About Computer Accounts\n",
      "Mastering Group Policy: Windows Server 2019 and Server 2016\n",
      "PowerShell for Active Directory Administrators\n",
      "Complete Windows Server 2016 Administration Course\n",
      "Windows Server 2019: Active Directory, GPO, R. Server Access\n",
      "Getting Started with Microsoft Active Directory\n",
      "Azure Active Directory: Basics\n",
      "Comprehensive DNS Security Attacks and Defenses\n",
      "CompTIA Network+ Cert (N10-007): IP Routing & Virtual LANs\n",
      "Active Directory Administration for Helpdesk Technicians\n",
      "CCIE Routing & Switching Version 5.0 - VPN\n",
      "Introduction to virtualization with VMware\n",
      "Deep Dive into Azure Active Directory (Azure AD)\n",
      "Juniper JNCIA-Junos (JN0-102)\n",
      "Managing and Automating Active Directory with PowerShell\n",
      "Learning Windows Server 2019\n",
      "SWITCH: Implementing Cisco IP Switched Networks\n",
      "Part A - Networking Projects - Implement TCP/IP Stack in C\n",
      "Windows Server 2019 Admin: Active Directory, DNS, GPO, DHCP\n",
      "Build Your Own Cisco SD-WAN (Viptela) Lab\n",
      "Active Directory Pentesting With Kali Linux - Red Team\n",
      "Cisco 300-101 - ROUTE - Implementing Cisco IP Routing\n",
      "[Active Directory] Management using Windows PowerShell\n",
      "Azure Active Directory PowerShell for Microsoft Office 365\n",
      "TCP/IP Training Video A Definitive & Easy To Follow Course\n",
      "Networking Foundations: Network Media (WANs)\n",
      "Powershell and Windows Server: 24+ Hours Bootcamp with Labs\n",
      "Mastering DNS on Windows Server 2016\n",
      "TCP/IP & OSI Models for Beginners\n",
      "Networking Foundations: Network Media (WANs)\n",
      "Cisco - TCP/IP & OSI Network Architecture Models\n",
      "Networking Foundations: Wide Area Networks (WANs)\n",
      "Course 4: MCSA Windows Server 2019 Enterprise Network\n",
      "Cisco ASA Firewall Lab Guide | IPSec VPN Troubleshoot\n",
      "Java Network Programming - TCP/IP Socket Programming\n",
      "Juniper Basics\n",
      "Network Programming Masterclass™:Java Socket, TCP/IP, Server\n",
      "Active Directory Pentesting Full Course - Red Team Hacking\n",
      "Virtual Private Networks for beginners - VPN, Cisco training\n",
      "Manage And Secure Your DNS In The Cloud With AWS Route 53\n",
      "Domain Name System (DNS) Administration- Windows Server 2016\n",
      "Windows Users guide to Linux\n",
      "Cisco SD-WAN Operation and Deployment (ENSDW)\n",
      "Identity & Access Management - Azure Active Directory - 2021\n",
      "VMware Workstation Pro 12: A Virtualization Beginners Course\n",
      "TCP/IP Socket Programming HandsOn-Windows & Linux in C & C++\n",
      "Install and Configure Windows Server 2019: get a job in IT\n",
      "Windows Server 2019: DHCP and DNS\n",
      "Internet Security: A Hands-on Approach\n",
      "Windows Server 2016: Install and Configure Active Directory\n",
      "CompTIA Network+ (N10-007) Cert Prep: 3 The World of TCP/IP\n",
      "Windows Server 2022: Install and Configure Active Directory\n",
      "Networking Foundations: Servers\n",
      "Active Directory and Windows Server 21+ Hour with Labs\n",
      "Windows Server 2016 Practical Guide with Advance Features\n",
      "Cisco SD-WAN (Viptela) with Lab Access\n",
      "Windows Active Directory for IT Security Adepts\n",
      "Windows Server 2016: Active Directory and Group Policy, GPO\n",
      "Active Directory For Beginners. Manage Users & Groups Today!\n",
      "Cisco Enterprise Networks: Basic Networking and IP Fundamentals\n",
      "Securing Windows Server 2016 Virtualization\n",
      "Windows Server 2016 Active Directory DNS DHCP File Server\n",
      "Learn TCP/IP - Computer Networking fundamentals\n",
      "Mastering and Implementing Azure Active Directory\n",
      "Azure Active Directory training\n",
      "The Complete Active Directory Course | IT Support\n",
      "Microsoft Active Directory Essentials on Windows Server 2019\n",
      "Windows Server 2016 with PowerShell: Active Directory\n",
      "DNS basics - Understand, setup and manage your own domains.\n",
      "Active Directory Administration with PowerShell\n",
      "Active Directory: Advanced AD DS infrastructure management\n",
      "Linux Practical Security\n",
      "Windows Server Hyper-V and Virtualization\n",
      "Active Directory Domain Services\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CONFIGURATION FOR RECOMMENDER MODULE\n",
    "# DATA FILE PATH\n",
    "tfidf_data_filepath = ('Feature Map/tfidf_data.pickle')\n",
    "categorical_data_filepath = 'Feature Map/categorical_data.pickle'\n",
    "tfidf_vectorizer_filepath = 'Feature Map/tfidf_vectorizer.pickle'\n",
    "# TEXT BASED RECOMMENDATION THRESHOLD\n",
    "text_thres = 0.2\n",
    "# MINIMUM FREE COURSE COUNT THRESHOLD\n",
    "free_show_thres = 20\n",
    "# RECOMMENDATION RESULTS SIZE\n",
    "recommend_topn = 100\n",
    "# DEFAULT POPULAR RESULTS SIZE\n",
    "recommend_default_topn = 50\n",
    "#multiplier=5\n",
    "ainput = ['Network Architect', 0, 0, 0]  # what to learn, difficulty,duration.free\n",
    "\n",
    "rawdata_rating = rawdata['popularity_index']\n",
    "a=load_pickle(tfidf_data_filepath)\n",
    "b=load_pickle(categorical_data_filepath)\n",
    "c=load_pickle(tfidf_vectorizer_filepath)\n",
    "idx=recommend(ainput,rawdata_rating,c,a,b)      \n",
    "idx=recommend_job_role_based(ainput,rawdata_rating,c,a,b)\n",
    "print(len(idx))\n",
    "for i in idx:\n",
    "    print(rawdata['title'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb=pd.read_csv('job_skills.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Docker', 'Ubuntu', 'Proxy Servers', 'Kubernetes', 'Ansible', 'LVM', 'Git', 'RedHat', 'EC2', 'SSL/TLS', 'Monitoring and logging tools', 'Prometheus', 'Automation tools', 'Azure', 'Linux', 'Bash Shell', 'Cloud computing', 'Networking', 'OpenStack', 'AWS', 'Amazon S3', 'Continuous integration/continuous deployment (CI/CD)', 'Grafana', 'TCP/IP', 'Fedora', 'Containerization technologies', 'Zabbix', 'Load Balancing', 'Perl', 'ELB', 'Firewalls', 'Google Cloud Platform', 'EFS', 'Ruby', 'Route 53', 'Vulnerability Scanning', 'Terraform', 'CentOS', 'Security and compliance', 'ELK Stack', 'Auto Scaling', 'Jenkins', 'DNS', 'Java', 'Scripting languages', 'Penetration Testing', 'Python']\n",
      "28\n",
      "DevOps , CI/CD(Continuous Integration/Delivery for Beginners\n",
      "Amazon EC2 Load Balancers\n",
      "Devops Tools and AWS for Java Microservice Developers\n",
      "DevOps Foundations: Continuous Delivery/Continuous Integration\n",
      "Master CI/CD for Xamarin\n",
      "DevOps Foundations: Continuous Delivery/Continuous Integration\n",
      "Continuous Integration: Tools\n",
      "Master CI/CD for React Native\n",
      "Learn DevOps: Docker, Kubernetes, Terraform and Azure DevOps\n",
      "Continuous Integration and Deployment\n",
      "Devops Fundamentals - CI/CD with AWS +Docker+Ansible+Jenkins\n",
      "Master CI/CD for Android Developers\n",
      "AWS: Get Started with EC2 Load Balancer & Auto-Scaling Group\n",
      "Introduction to Continuous Integration & Continuous Delivery\n",
      "Project in DevOps: Jenkins CI/CD for Kubernetes Deployments\n",
      "Master CI/CD for iOS Developers\n",
      "DevOps Certification Training Course\n",
      "Build with Amazon EC2\n",
      "AWS Solutions Architect Certification Training Course\n",
      "Amazon Route 53 - Domains\n",
      "Introduction to Amazon Route 53\n",
      "Continuous Integration concepts and tools\n",
      "Jenkins: continuous integration & DevOps with Java and .NET\n",
      "Bash Shell scripting and automation\n",
      "Selenium WebDriver with CI/CD,AWS,Jenkins,Docker,Grid,GitHub\n",
      "DevOps: Build Complete CI/CD Jenkins Pipeline With AWS\n",
      "Mastering Jenkins CI with Amazon AWS: Build DevOps Pipeline\n",
      "AWS EC2 - Be the best\n",
      "Docker\n",
      "Apache Airflow 2.0 using Docker, Docker Swarm\n",
      "Docker Masterclass: Hands-on DevOps™ for Developers\n",
      "Docker for Python Django Developers\n",
      "More than Certified in Docker\n",
      "More than Certified in Terraform\n",
      "Ubuntu\n",
      "Building an Ubuntu Server\n",
      "Linux Foundation Cert Prep: Essential Commands (Ubuntu)\n",
      "Linux Foundation Cert Prep: Network Security (Ubuntu)\n",
      "Linux Foundation Cert Prep: Email Services (Ubuntu)\n",
      "Linux Foundation Cert Prep: HTTP Services (Ubuntu)\n",
      "Proxy Servers\n",
      "Advanced Django: Building a Blog\n",
      "API Design and Fundamentals of Google Cloud's Apigee API Platform\n",
      "SQL Server 2014 Essential Training\n",
      "Master How to Install a Windows Server for a Small Business\n",
      "Microsoft Windows Server 2016 - Hands-on Training Part II\n",
      "Kubernetes\n",
      "Master Microservices with Spring, Docker, Kubernetes\n",
      "Kubernetes Mastery on AWS\n",
      "Kubernetes: Cloud Native Ecosystem\n",
      "Kubernetes: Native Tools\n",
      "Learn DevOps: On-Prem or Cloud Agnostic Kubernetes\n",
      "Ansible\n",
      "Complete Ansible Bootcamp: Go from zero to hero in Ansible\n",
      "DevOps: CI/CD with Jenkins Nexus Ansible Docker Terraform\n",
      "Learning Ansible\n",
      "Red Hat Certified Engineer (EX294) Cert Prep: 1 Foundations of Ansible\n",
      "Master Network Automation with Python for Network Engineers\n",
      "LVM\n",
      "Linux Logical Volume Manager (LVM)\n",
      "Linux  RAID & LVM Management\n",
      "Git\n",
      "Git Intermediate Techniques\n",
      "Learning Git and GitHub\n",
      "Git Command Line for Beginners\n",
      "DevOps Project: CICD with Git GitLab Jenkins  and Laravel\n",
      "8 Git Commands You Should Know\n",
      "RedHat\n",
      "Linux Redhat Certified System Administrator (RHCSA 8)\n",
      "Understanding and Using Essential Tools for Enterprise Linux 7\n",
      "Storage Area Network with Openfiler Linux\n",
      "Ultimate Ansible Bootcamp by School of Devops®\n",
      "IBM MQ Administration basics in Redhat Linux for beginners\n",
      "EC2\n",
      "Devops Tools and AWS for Java Microservice Developers\n",
      "DevOps Deployment Automation with Terraform, AWS and Docker\n",
      "Amazon EC2 Load Balancers\n",
      "Deploying web apps for new developers on AWS ec2\n",
      "Learning AWS CloudFormation\n",
      "SSL/TLS\n",
      "SSL Certificates for Web Developers\n",
      "Install NGINX, PHP, MySQL, SSL & WordPress on Ubuntu\n",
      "Introduction to NGINX\n",
      "Learning SSL/TLS\n",
      "SSL/TLS Fundamentals\n",
      "Monitoring and logging tools\n",
      "CompTIA Network+ Cert(N10-007): Monitoring & Troubleshooting\n",
      "Architecting with Google Kubernetes Engine: Production\n",
      "Learning Cloud Computing: Monitoring and Operations\n",
      "Linux Foundation Cert Prep: Service Configuration (Ubuntu)\n",
      "Azure Apps: Diagnostics, Instrumentation, and Logging\n",
      "Prometheus\n",
      "Prometheus Alerting and Monitoring\n",
      "Ultimate Prometheus\n",
      "Master DevOps Monitoring with Prometheus\n",
      "Prometheus | The Complete Hands-On for Monitoring & Alerting\n",
      "Kubernetes: Monitoring with Prometheus\n",
      "Automation tools\n",
      "Google IT Automation with Python\n",
      "Cypress: Web Automation Testing from Zero to Hero\n",
      "API automation for SDET - Bootcamp (RestAssured/ HttpClient)\n",
      "REST Assured API Automation + Framework: From Zero to Hero!\n",
      "Learn Python: The Complete Python Automation Course!\n",
      "Azure\n",
      "Planning for Azure Active Directory\n",
      "Angular: Building on Azure Microservices\n",
      "Azure Resources for AWS Architects\n",
      "Azure DevOps: Continuous Delivery with YAML Pipelines\n",
      "Automation with Azure Powershell and ARM Templates\n",
      "Linux\n",
      "Linux Foundation Cert Prep: Email Services (Ubuntu)\n",
      "Create Your Own DVR with Mythbuntu (Ubuntu + MythTV)\n",
      "Learning Kali Linux\n",
      "Linux Foundation Cert Prep: Network Administration (Ubuntu)\n",
      "The Practical Linux Guide for Beginners\n",
      "Bash Shell\n",
      "Learning Bash Scripting\n",
      "The Practical Linux Guide for Beginners\n",
      "Bash Mastery: The Complete Guide to Bash Shell Scripting\n",
      "Learning Linux Shell Scripting\n",
      "Secure Shell Fundamentals - Learn SSH By Configuring It\n",
      "Cloud computing\n",
      "Learning Cloud Computing: Core Concepts\n",
      "CCSP Cert Prep: 4 Cloud Application Security\n",
      "Amazon Web Services - Web Hosting & Cloud Computing With AWS\n",
      "Spring Cloud Fundamentals\n",
      "Google Cloud Platform Essential Training for Administrators\n",
      "Networking\n",
      "Linux System Engineer: Networking and SSH\n",
      "Learn and Understand Wireless Technologies 2021 (CWNA)\n",
      "Docker Essential Training: 5 Networking\n",
      "Windows 7: Networking and Security\n",
      "VMware vSphere 6.5 Advanced Networking\n",
      "OpenStack\n",
      "OpenStack Basic to Advanced Installation and Administration\n",
      "Fundamentals of the OpenStack Cloud with Hands-on Labs\n",
      "Hands-on introduction to OpenStack, Docker & Cloud Computing\n",
      "Private Cloud Management on IBM Power Systems\n",
      "Red Hat OpenStack Administration I\n",
      "AWS\n",
      "AWS Cloud Development Kit - From Beginner to Professional\n",
      "AWS Certified Developer Associate Exam Training 2021 [NEW]\n",
      "AWS for Architects: Network and Storage Design\n",
      "Amazon Web Services - Web Hosting & Cloud Computing With AWS\n",
      "AWS for Developers: S3\n",
      "Amazon S3\n",
      "Building Intelligent Chatbots on AWS\n",
      "Amazon Web Services - Web Hosting & Cloud Computing With AWS\n",
      "AWS Machine Learning Engineer\n",
      "Building Serverless Apps on AWS\n",
      "AWS for Developers: S3\n",
      "Continuous integration/continuous deployment (CI/CD)\n",
      "DevOps Foundations: Continuous Delivery/Continuous Integration\n",
      "DevOps On AWS\n",
      "DevOps: CI/CD with Jenkins using Pipelines:Complete Tutorial\n",
      "DevOps with AWS\n",
      "Master CI/CD for React Native\n",
      "Grafana\n",
      "Cloud Native Application Architecture\n",
      "Grafana Master Course - Time Series Data Visualization\n",
      "Prometheus | The Complete Hands-On for Monitoring & Alerting\n",
      "Grafana Beginners to Advance Crash Course 2021\n",
      "Grafana\n",
      "TCP/IP\n",
      "Network Security & Database Vulnerabilities\n",
      "CCNA Service Provider - PART 3/4\n",
      "Networking Foundations: IP Addressing\n",
      "Cisco CCNA (200-301) Cert Prep: IP Connectivity and Services\n",
      "Cisco CCNA (200-301) Cert Prep: IP Connectivity and Services\n",
      "Fedora\n",
      "Fedora Linux from Scratch\n",
      "Learning Fedora Linux\n",
      "Fedora Basics\n",
      "Containerization technologies\n",
      "Beginner's Guide to Information Technology\n",
      "Containerization using DOCKER\n",
      "Robot Framework with Selenium - Web Automation\n",
      "Docker for .NET Developers with Visual Studio\n",
      "Information Technology Essentials\n",
      "Zabbix\n",
      "Zabbix Network Monitoring Beginner To Pro In 7 Days\n",
      "Zabbix Server: Installing and Configuring from Scratch\n",
      "Zabbix Network Monitoring Essentials\n",
      "Load Balancing\n",
      "VRRP on MikroTik with Load-Balancing & Failover\n",
      "Managing Security in Google Cloud\n",
      "Exchange 2016: Client Access Services\n",
      "Elastic Google Cloud Infrastructure: Scaling and Automation\n",
      "Amazon EC2 Load Balancers\n",
      "Perl\n",
      "Perl 5 Essential Training\n",
      "Become a Professional Programmer\n",
      "Learn Perl 5 By Doing It\n",
      "Perl Programming for Beginners\n",
      "The Complete Regular Expressions Course with Exercises 2020\n",
      "ELB\n",
      "Devops Tools and AWS for Java Microservice Developers\n",
      "Introduction to Amazon Elastic Load Balancer - Classic\n",
      "Firewalls\n",
      "Linux Super Cert Prep: Get Certified as a Linux System Admin\n",
      "Implementing a Cisco ASA Firewall 9.X - All - in - One\n",
      "Palo Alto Networks Automation with API, Python & Ansible\n",
      "Cisco Network Security: Cisco Firewall Technologies\n",
      "Firewall Administration Essential Training\n",
      "Google Cloud Platform\n",
      "Google Cloud Platform Essential Training (2019)\n",
      "Learning Cloud Computing: Core Concepts\n",
      "Managing Security in Google Cloud\n",
      "Google Cloud Big Data and Machine Learning Fundamentals\n",
      "Essential Google Cloud Infrastructure: Foundation\n",
      "EFS\n",
      "Managing, Monitoring, and Optimizing your Amazon Elastic File System (Amazon EFS) Solution\n",
      "Designing and Deploying an Amazon Elastic File System (Amazon EFS) Solution\n",
      "Securing Data in Amazon Elastic File System (Amazon EFS)\n",
      "Amazon Elastic File System (Amazon EFS) Primer\n",
      "AWS DataSync Primer\n",
      "Ruby\n",
      "Installing and Running Ruby on Rails 5: Mac\n",
      "2020 Complete Ruby on Rails 6 Bootcamp: Learn Ruby on Rails\n",
      "Testing Ruby with RSpec: The Complete Guide\n",
      "Ruby on Rails 6 Essential Training\n",
      "Essential Gems for Your Rails Projects\n",
      "Route 53\n",
      "CCNP R&S – 300-101 Route Labs Only\n",
      "CCNP ROUTE 300-101 Deep Dive:\n",
      "CCNP Route 642-902 Implementing Cisco IP Routing\n",
      "Full Android 11 Masterclass Course with Java | 53 Hours\n",
      "Cisco 300-101 - ROUTE - Implementing Cisco IP Routing\n",
      "Vulnerability Scanning\n",
      "The Art of Doing:  Master Networks and Network Scanning\n",
      "Reverse Engineering Foundations: Product Design\n",
      "CompTIA PenTest+ (PT0-001): 2 Survey the Target\n",
      "Learning Kali Linux\n",
      "Learning Kali Linux\n",
      "Terraform\n",
      "Terraform - From Zero to Certified Professional\n",
      "Advanced Terraform\n",
      "Hashicorp Terraform Associate Certification Preparation 2021\n",
      "DevOps Deployment Automation with Terraform, AWS and Docker\n",
      "More than Certified in Terraform\n",
      "CentOS\n",
      "Linux: Desktops and Remote Access\n",
      "The Perfect NGINX Server - CentOS Edition\n",
      "Red Hat Enterprise Linux 8 / CentOS 8 In Action\n",
      "CentOS 7 Linux Server: Alternative to Red Hat Enterprise\n",
      "Linux Administration: The Complete Linux Bootcamp 2021\n",
      "Security and compliance\n",
      "Learn FISMA Compliance (RMF steps 1-5)\n",
      "Mitigating Security Vulnerabilities on Google Cloud\n",
      "The Beginners Guide to Practical Cyber Security Skills\n",
      "Cloud Security Considerations for Government and the Military\n",
      "PCI DSS Compliance : The A-Z™ Information Security Course\n",
      "ELK Stack\n",
      "Getting Started as a Full-Stack Web Developer\n",
      "The Complete MERN Stack Authentication With Source Code\n",
      "Succeeding in Web Development: Full Stack and Front End\n",
      "React: Creating and Hosting a Full-Stack Site\n",
      "Learning the Elastic Stack\n",
      "Auto Scaling\n",
      "Devops Tools and AWS for Java Microservice Developers\n",
      "Master iOS Auto Layout (Swift/Xcode)\n",
      "AWS: Automation and Optimization\n",
      "iOS Development: Auto Layout Programmatically\n",
      "Amazon EC2 Load Balancers\n",
      "Jenkins\n",
      "DevOps: CI/CD with Jenkins Nexus Ansible Docker Terraform\n",
      "Jenkins Essential Training\n",
      "Learning Jenkins\n",
      "DevOps Tools: Optimizing The Software Development Lifecycle\n",
      "Devops Tools and AWS for Java Microservice Developers\n",
      "DNS\n",
      "An Introduction to Computer Networking for Teachers\n",
      "Networking Foundations: IP Addressing\n",
      "Windows 7: Networking and Security\n",
      "DNSSec - Secure DNS\n",
      "Basics of BIND DNS Server\n",
      "Java\n",
      "Java Certification SE 1Z0-808 Masterclass + Practice Exams™\n",
      "The complete Java Android App development Bootcamp\n",
      "Fundamentals of Java with NetBeans\n",
      "Learning Java\n",
      "Java EE 8: JavaServer Faces JSF 2.3\n",
      "Scripting languages\n",
      "CompTIA A+ (220-1002) Cert Prep 4: Command-Line Interface and Scripting Languages\n",
      "Learning Bash Scripting (2013)\n",
      "Learning Linux Shell Scripting\n",
      "Learning C#\n",
      "Advanced Python\n",
      "Penetration Testing\n",
      "Web Automation and Testing using Playwright\n",
      "Complete Python 3 Ethical Hacking: Beginner To Advanced!\n",
      "Linux Privilege Escalation for OSCP & Beyond!\n",
      "Learn Ethical Hacking & Penetration Testing\n",
      "Windows Privilege Escalation for OSCP & Beyond!\n",
      "Python\n",
      "Learn Python3 Programming\n",
      "Human Generator Mobile App with Flutter & Python\n",
      "Full Stack Web Development Bootcamp with React and Python\n",
      "Object Oriented Programming with Python\n",
      "Python Game Development - Create a Tetris with PyGame\n"
     ]
    }
   ],
   "source": [
    "ainput = ['DevOps Engineer', 0, 0, 0]\n",
    "      \n",
    "idx=recommend_job_role_based(ainput,rawdata_rating,c,a,b)\n",
    "print(len(idx))\n",
    "    \n",
    "for i in idx:\n",
    "            print(rawdata['title'][i])\n",
    "if len(idx)<50:\n",
    "    v=jb[jb.job_role=='DevOps Engineer']\n",
    "    j=v.skill_set.str.split(',')\n",
    "    for i in j:\n",
    "        for k in i:\n",
    "        \n",
    "        \n",
    "            ainput = [k, 0, 0, 0]\n",
    "            idx=recommend(ainput,rawdata_rating,c,a,b)      \n",
    "            \n",
    "\n",
    "            print(k)\n",
    "            for ink in idx[:5]:\n",
    "               \n",
    "                print(rawdata['title'][ink])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   .NET  3D modeling and animation  ANOVA  API development  ASP.NET  AWS  \\\n",
      "0     0                          0      1                0        0    1   \n",
      "\n",
      "   Active Directory  Agile  Agile methodologies  Algorithms  ...  Waterfall  \\\n",
      "0                 0      0                    0           0  ...          0   \n",
      "\n",
      "   Web development  Web performance optimization  Windows  Windows Server  \\\n",
      "0                0                             0        0               0   \n",
      "\n",
      "   Wireframing  Wireframing and prototyping tools  Zabbix  jQuery  macOS  \n",
      "0            0                                  0       0       0      0  \n",
      "\n",
      "[1 rows x 207 columns]\n"
     ]
    }
   ],
   "source": [
    "jbdbd=pd.read_csv('job_skills.csv')\n",
    "dummies=jbdbd.skill_set.str.get_dummies(\",\")\n",
    "  \n",
    "# display\n",
    "print(dummies.head(1))\n",
    "\n",
    "dummies.insert(loc=0, column='job_role', value=jbdbd.job_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_role</th>\n",
       "      <th>.NET</th>\n",
       "      <th>3D modeling and animation</th>\n",
       "      <th>ANOVA</th>\n",
       "      <th>API development</th>\n",
       "      <th>ASP.NET</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Active Directory</th>\n",
       "      <th>Agile</th>\n",
       "      <th>Agile methodologies</th>\n",
       "      <th>...</th>\n",
       "      <th>Waterfall</th>\n",
       "      <th>Web development</th>\n",
       "      <th>Web performance optimization</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Windows Server</th>\n",
       "      <th>Wireframing</th>\n",
       "      <th>Wireframing and prototyping tools</th>\n",
       "      <th>Zabbix</th>\n",
       "      <th>jQuery</th>\n",
       "      <th>macOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               job_role  .NET  3D modeling and animation  ANOVA  \\\n",
       "0          Data Analyst     0                          0      1   \n",
       "1        Data Scientist     0                          0      0   \n",
       "2    Software Developer     1                          0      0   \n",
       "3  Full Stack Developer     0                          0      0   \n",
       "4         Web Developer     0                          0      0   \n",
       "\n",
       "   API development  ASP.NET  AWS  Active Directory  Agile  \\\n",
       "0                0        0    1                 0      0   \n",
       "1                0        0    1                 0      0   \n",
       "2                1        0    0                 0      1   \n",
       "3                1        1    0                 0      1   \n",
       "4                0        0    0                 0      1   \n",
       "\n",
       "   Agile methodologies  ...  Waterfall  Web development  \\\n",
       "0                    0  ...          0                0   \n",
       "1                    0  ...          0                0   \n",
       "2                    0  ...          0                1   \n",
       "3                    1  ...          0                0   \n",
       "4                    0  ...          0                0   \n",
       "\n",
       "   Web performance optimization  Windows  Windows Server  Wireframing  \\\n",
       "0                             0        0               0            0   \n",
       "1                             0        0               0            0   \n",
       "2                             0        1               0            0   \n",
       "3                             0        0               0            0   \n",
       "4                             1        0               0            0   \n",
       "\n",
       "   Wireframing and prototyping tools  Zabbix  jQuery  macOS  \n",
       "0                                  0       0       0      0  \n",
       "1                                  0       0       0      0  \n",
       "2                                  0       0       0      1  \n",
       "3                                  0       0       1      0  \n",
       "4                                  0       0       1      0  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.to_csv('jobencode.csv', index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_role</th>\n",
       "      <th>skill_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Statistical analysis,ANOVA,MySQL,SQL,Problem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Statistical analysis,Hadoop,SQL,Deep learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>API development,Docker,Windows,Kubernetes,MySQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Semantic UI,API development,MySQL,Git,Oracle,A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>SQL,Responsive design,Git,Agile,Vue.js,PHP,Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               job_role                                          skill_set\n",
       "0          Data Analyst  Statistical analysis,ANOVA,MySQL,SQL,Problem s...\n",
       "1        Data Scientist  Statistical analysis,Hadoop,SQL,Deep learning,...\n",
       "2    Software Developer  API development,Docker,Windows,Kubernetes,MySQ...\n",
       "3  Full Stack Developer  Semantic UI,API development,MySQL,Git,Oracle,A...\n",
       "4         Web Developer  SQL,Responsive design,Git,Agile,Vue.js,PHP,Jav..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jbdbd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Job Role  Similarity\n",
      "4               Web Developer    0.314730\n",
      "3        Full Stack Developer    0.177508\n",
      "13             UI/UX Designer    0.142889\n",
      "2          Software Developer    0.112021\n",
      "0                Data Analyst    0.109152\n",
      "1              Data Scientist    0.080037\n",
      "9      Database Administrator    0.053766\n",
      "10            DevOps Engineer    0.031166\n",
      "5   Cloud Solutions Architect    0.000000\n",
      "6       Cybersecurity Analyst    0.000000\n",
      "7       Network Administrator    0.000000\n",
      "8           Network Architect    0.000000\n",
      "11            Systems Analyst    0.000000\n",
      "12             Game Developer    0.000000\n",
      "14                 IT Manager    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# user skill set\n",
    "user_skills = \"Python,CSS,HTML,sql\"\n",
    "\n",
    "# job required skills\n",
    "job_skills = jbdbd.skill_set\n",
    "\n",
    "# text preprocessing\n",
    "user_skills = user_skills.lower().replace(\",\", \" \")\n",
    "job_skills = [skills.lower().replace(\",\", \" \") for skills in job_skills]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "job_skills_tfidf = tfidf.fit_transform(job_skills)\n",
    "user_skills_tfidf = tfidf.transform([user_skills])\n",
    "\n",
    "# cosine similarity\n",
    "similarity_matrix = cosine_similarity(user_skills_tfidf, job_skills_tfidf)\n",
    "\n",
    "# create a dataframe with job roles and their similarity scores\n",
    "jobs_df = pd.DataFrame({'Job Role': jbdbd.job_role,\n",
    "                        'Similarity': similarity_matrix[0]})\n",
    "\n",
    "# sort by similarity score in descending order\n",
    "jobs_df = jobs_df.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "# print the dataframe\n",
    "print(jobs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Scientist', 'Database Administrator', 'Software Developer']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('jobencode.csv', index_col='job_role')\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cos_sim = cosine_similarity(df)\n",
    "\n",
    "# Get the indices of the most similar job roles\n",
    "job_indices = pd.Series(df.index)\n",
    "\n",
    "def get_similar_jobs(job_title, n=3):\n",
    "    # Find the index of the job title\n",
    "    idx = job_indices[job_indices == job_title].index[0]\n",
    "\n",
    "    # Get the cosine similarities for the job\n",
    "    sim_scores = list(enumerate(cos_sim[idx]))\n",
    "\n",
    "    # Sort the jobs by similarity score\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the most similar jobs\n",
    "    sim_indices = [i[0] for i in sim_scores[1:n+1]]\n",
    "\n",
    "    # Return the most similar job titles\n",
    "    return list(job_indices.iloc[sim_indices])\n",
    "\n",
    "# Example usage:\n",
    "similar_jobs = get_similar_jobs('Data Analyst', n=3)\n",
    "print(similar_jobs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
