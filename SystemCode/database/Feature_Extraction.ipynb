{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "-------------------------\n",
      "pandas:   1.5.2\n",
      "numpy:    1.21.5\n",
      "sklearn:  1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Load All Necessary Packages\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import sqlite3\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rake_nltk import Rake\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "seed = 18\n",
    "\n",
    "print('Versions of key libraries')\n",
    "print('-------------------------')\n",
    "print('pandas:  ', pd.__version__)\n",
    "print('numpy:   ', np.__version__)\n",
    "print('sklearn: ', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check & Query\n",
    "filename = 'app_database.db'\n",
    "table_name = 'course'\n",
    "sqlite_conn = sqlite3.connect(filename)\n",
    "\n",
    "# Query Table\n",
    "rawdata = pd.read_sql('SELECT * FROM ' + table_name, sqlite_conn, index_col='courseID')\n",
    "\n",
    "sqlite_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20475, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>categories</th>\n",
       "      <th>description_short</th>\n",
       "      <th>description_long</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>free_option</th>\n",
       "      <th>number_of_enroll</th>\n",
       "      <th>rating</th>\n",
       "      <th>paid_option</th>\n",
       "      <th>language</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>platform</th>\n",
       "      <th>provider</th>\n",
       "      <th>image_url</th>\n",
       "      <th>popularity_index</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>courseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Getting Started with AWS Mainframe Modernizati...</td>\n",
       "      <td>https://explore.skillbuilder.aws/learn/course/...</td>\n",
       "      <td>Computer Science , Cloud , AWS ,Cloud Computing</td>\n",
       "      <td>Description not availabel</td>\n",
       "      <td>Description not availabel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>AWS Skill Builder</td>\n",
       "      <td>https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>getting, start, aws, mainframe, modernization,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cloud for CEOs</td>\n",
       "      <td>https://explore.skillbuilder.aws/learn/course/...</td>\n",
       "      <td>Computer Science , Cloud , AWS ,Cloud Computing</td>\n",
       "      <td>This course provides CEOs and presidents a hig...</td>\n",
       "      <td>This course provides CEOs and presidents a hig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>AWS Skill Builder</td>\n",
       "      <td>https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>cloud, ceo, course, provide, ceo, president, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Getting Started with AWS Mainframe Modernizati...</td>\n",
       "      <td>https://explore.skillbuilder.aws/learn/course/...</td>\n",
       "      <td>Computer Science , Cloud , AWS ,Cloud Computing</td>\n",
       "      <td>The AWS Mainframe Modernization service helps ...</td>\n",
       "      <td>The AWS Mainframe Modernization service helps ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>AWS Skill Builder</td>\n",
       "      <td>https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>getting, start, aws, mainframe, modernization,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Introduction to Robotics on AWS</td>\n",
       "      <td>https://explore.skillbuilder.aws/learn/course/...</td>\n",
       "      <td>Computer Science , Cloud , AWS ,Cloud Computing</td>\n",
       "      <td>The robotics industry is growing at a rapid ra...</td>\n",
       "      <td>The robotics industry is growing at a rapid ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>AWS Skill Builder</td>\n",
       "      <td>https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>introduction, robotic, aw, robotic, industry, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Getting Started with Bottlerocket</td>\n",
       "      <td>https://explore.skillbuilder.aws/learn/course/...</td>\n",
       "      <td>Computer Science , Cloud , AWS ,Cloud Computing</td>\n",
       "      <td>Bottlerocket is a Linux-based, open-source ope...</td>\n",
       "      <td>Bottlerocket is a Linux-based, open-source ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>AWS Skill Builder</td>\n",
       "      <td>https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...</td>\n",
       "      <td>0.415333</td>\n",
       "      <td>getting, start, bottlerocket, bottlerocket, li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "courseID                                                      \n",
       "1         Getting Started with AWS Mainframe Modernizati...   \n",
       "2                                            Cloud for CEOs   \n",
       "3         Getting Started with AWS Mainframe Modernizati...   \n",
       "4                           Introduction to Robotics on AWS   \n",
       "5                         Getting Started with Bottlerocket   \n",
       "\n",
       "                                                        url  \\\n",
       "courseID                                                      \n",
       "1         https://explore.skillbuilder.aws/learn/course/...   \n",
       "2         https://explore.skillbuilder.aws/learn/course/...   \n",
       "3         https://explore.skillbuilder.aws/learn/course/...   \n",
       "4         https://explore.skillbuilder.aws/learn/course/...   \n",
       "5         https://explore.skillbuilder.aws/learn/course/...   \n",
       "\n",
       "                                               categories  \\\n",
       "courseID                                                    \n",
       "1         Computer Science , Cloud , AWS ,Cloud Computing   \n",
       "2         Computer Science , Cloud , AWS ,Cloud Computing   \n",
       "3         Computer Science , Cloud , AWS ,Cloud Computing   \n",
       "4         Computer Science , Cloud , AWS ,Cloud Computing   \n",
       "5         Computer Science , Cloud , AWS ,Cloud Computing   \n",
       "\n",
       "                                          description_short  \\\n",
       "courseID                                                      \n",
       "1                                 Description not availabel   \n",
       "2         This course provides CEOs and presidents a hig...   \n",
       "3         The AWS Mainframe Modernization service helps ...   \n",
       "4         The robotics industry is growing at a rapid ra...   \n",
       "5         Bottlerocket is a Linux-based, open-source ope...   \n",
       "\n",
       "                                           description_long  difficulty  \\\n",
       "courseID                                                                  \n",
       "1                                 Description not availabel           0   \n",
       "2         This course provides CEOs and presidents a hig...           0   \n",
       "3         The AWS Mainframe Modernization service helps ...           0   \n",
       "4         The robotics industry is growing at a rapid ra...           0   \n",
       "5         Bottlerocket is a Linux-based, open-source ope...           0   \n",
       "\n",
       "          duration  free_option  number_of_enroll  rating paid_option  \\\n",
       "courseID                                                                \n",
       "1                0            1                 0     5.0           0   \n",
       "2                0            1                 0     5.0           0   \n",
       "3                0            1                 0     5.0           0   \n",
       "4                0            1                 0     5.0           0   \n",
       "5                0            1                 0     5.0           0   \n",
       "\n",
       "         language subtitle  platform           provider  \\\n",
       "courseID                                                  \n",
       "1         English  English         0  AWS Skill Builder   \n",
       "2         English  English         0  AWS Skill Builder   \n",
       "3         English  English         0  AWS Skill Builder   \n",
       "4         English  English         0  AWS Skill Builder   \n",
       "5         English  English         0  AWS Skill Builder   \n",
       "\n",
       "                                                  image_url  popularity_index  \\\n",
       "courseID                                                                        \n",
       "1         https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...          0.415333   \n",
       "2         https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...          0.415333   \n",
       "3         https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...          0.415333   \n",
       "4         https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...          0.415333   \n",
       "5         https://ccweb.imgix.net/https%3A%2F%2Fwww.clas...          0.415333   \n",
       "\n",
       "                                                   keywords  \n",
       "courseID                                                     \n",
       "1         getting, start, aws, mainframe, modernization,...  \n",
       "2         cloud, ceo, course, provide, ceo, president, h...  \n",
       "3         getting, start, aws, mainframe, modernization,...  \n",
       "4         introduction, robotic, aw, robotic, industry, ...  \n",
       "5         getting, start, bottlerocket, bottlerocket, li...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rawdata.shape)\n",
    "rawdata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction for Text Based Data\n",
    "### i) Extract Text Based Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20475,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1    Getting Started with AWS Mainframe Modernizati...\n",
       "2                                       Cloud for CEOs\n",
       "3    Getting Started with AWS Mainframe Modernizati...\n",
       "4                      Introduction to Robotics on AWS\n",
       "5                    Getting Started with Bottlerocket\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Text Based Columns - Name, Categories, Short Description and Long Description\n",
    "rawdata_name = rawdata['title']\n",
    "rawdata_cat = rawdata['categories']\n",
    "rawdata_sdesc = rawdata['description_short']\n",
    "rawdata_ldesc = rawdata['description_long']\n",
    "\n",
    "print(rawdata_name.shape)\n",
    "rawdata_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1                            Description not availabel\n",
       "2    This course provides CEOs and presidents a hig...\n",
       "3    The AWS Mainframe Modernization service helps ...\n",
       "4    The robotics industry is growing at a rapid ra...\n",
       "5    Bottlerocket is a Linux-based, open-source ope...\n",
       "Name: description_long, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_ldesc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1          Computer Science , Cloud , AWS ,Cloud Computing\n",
       "2          Computer Science , Cloud , AWS ,Cloud Computing\n",
       "3          Computer Science , Cloud , AWS ,Cloud Computing\n",
       "4          Computer Science , Cloud , AWS ,Cloud Computing\n",
       "5          Computer Science , Cloud , AWS ,Cloud Computing\n",
       "                               ...                        \n",
       "20471     Computer Networking, Network Model, Cryptogra...\n",
       "20472     Data Visualization, Business Analysis, Comput...\n",
       "20473     Computer Programming, Python Programming, Sta...\n",
       "20474     Data Architecture, Data Warehousing, Database...\n",
       "20475     Linear Algebra, Data Mining, Machine Learning...\n",
       "Name: categories, Length: 20475, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata_cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) Text Preprocessing\n",
    "# Text Preprocessing Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwordsdic = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocess(rawtext):\n",
    "    text = re.sub('([^\\x00-\\x7F])+','',rawtext) # Remove all non ASCII characters\n",
    "    text = text.lower() # lower casing all words\n",
    "    text = text.strip() # Remove White Spaces\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # Remove Punctuations\n",
    "    text = word_tokenize(text) # Tokenize\n",
    "    text = [word for word in text if word not in stopwordsdic] # Remove stopwords\n",
    "    text = [lemmatizer.lemmatize(word) for word in text] # Lemmatize words\n",
    "    bow  = ' '.join(text) # Create Bag-of-Words\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Text Preprocessing\n",
    "data_name = rawdata_name.apply(lambda x: '' if pd.isna(x) else text_preprocess(x)).astype(str)\n",
    "data_cat = rawdata_cat.apply(lambda x: '' if pd.isna(x) else text_preprocess(x)).astype(str)\n",
    "data_sdesc = rawdata_sdesc.apply(lambda x: '' if pd.isna(x) else text_preprocess(x)).astype(str)\n",
    "data_ldesc = rawdata_ldesc.apply(lambda x: '' if pd.isna(x) else text_preprocess(x)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1               computer science cloud aws cloud computing\n",
       "2               computer science cloud aws cloud computing\n",
       "3               computer science cloud aws cloud computing\n",
       "4               computer science cloud aws cloud computing\n",
       "5               computer science cloud aws cloud computing\n",
       "                               ...                        \n",
       "20471    computer networking network model cryptography...\n",
       "20472    data visualization business analysis computer ...\n",
       "20473    computer programming python programming statis...\n",
       "20474    data architecture data warehousing database ap...\n",
       "20475    linear algebra data mining machine learning di...\n",
       "Name: categories, Length: 20475, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ldesc.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) Keyword Extractions for Short and Long Description \n",
    "# Keyword Extraction Function \n",
    "\n",
    "The method used for keyword extraction is based on the Natural Language Processing (NLP) library called spaCy. It involves using spaCy's pre-trained English language model to tokenize the input text, remove stopwords and punctuation, and calculate the frequency of each remaining word in the text. The method then ranks the words based on their frequency and selects the top N words as the keywords for the text. The ranking is done using a normalization factor to account for the difference in frequency between different texts. The method returns a list of the top N keywords for the input text.\n",
    "The algorithm used here for keyword extraction is a simple frequency-based approach, where the frequency of each word in the text is calculated using the Counter function from the collections module. Then, the words are ranked based on their frequency, and the top n words are returned as keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def extract_keywords(text):\n",
    "    keywords=[]\n",
    "    if text !='':\n",
    "        doc = nlp(text.lower())\n",
    "\n",
    "        words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "        if len(words) == 0:\n",
    "            return []\n",
    "        word_freq = Counter(words)\n",
    "        max_freq = max(word_freq.values())\n",
    "        ranked_words = [(word, freq/max_freq) for word, freq in word_freq.items()]\n",
    "        ranked_words = sorted(ranked_words, key=lambda x: x[1], reverse=True)\n",
    "        keywords = [word for word, score in ranked_words]\n",
    "    return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply keyword extraction to short and long description\n",
    "\n",
    "\n",
    "data_sdesc_kw = data_sdesc.apply(lambda x: '' if pd.isna(x) else ' '.join(extract_keywords(x)))\n",
    "data_ldesc_kw = data_ldesc.apply(lambda x: '' if pd.isna(x) else ' '.join(extract_keywords(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1                                    description availabel\n",
       "2        cloud course provides ceo president high level...\n",
       "3        aws mainframe service modernization help migra...\n",
       "4        robotics industry growing rapid rate creating ...\n",
       "5        bottlerocket container software linux based op...\n",
       "                               ...                        \n",
       "20471    technology network course world internet creat...\n",
       "20472    course round world regatta lead boat mediterra...\n",
       "20473    design use designer focused fundamental course...\n",
       "20474    data big hadoop process course novice programm...\n",
       "20475    learning machine able course hand case house d...\n",
       "Name: description_long, Length: 20475, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ldesc_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "courseID\n",
       "1                                    description availabel\n",
       "2        cloud course provides ceo president high level...\n",
       "3        aws mainframe service modernization help migra...\n",
       "4        robotics industry growing rapid rate creating ...\n",
       "5        bottlerocket container software linux based op...\n",
       "                               ...                        \n",
       "20471    technology network course world internet creat...\n",
       "20472    course round world regatta lead boat mediterra...\n",
       "20473    design use designer focused fundamental course...\n",
       "20474    data big hadoop process course novice programm...\n",
       "20475    learning machine able course hand case house d...\n",
       "Name: description_short, Length: 20475, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sdesc_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'description availabel'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sdesc_kw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(data_sdesc_kw)+1):\n",
    "\n",
    "    if ('description availabel') in data_sdesc_kw[i]:\n",
    "        data_sdesc_kw[i]=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(data_ldesc_kw)+1):\n",
    "\n",
    "    if ('description availabel') in data_ldesc_kw[i]:\n",
    "        data_ldesc_kw[i]=''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Create Bag-of-words and Corresponding List of Tokens Per Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_name_npy = data_name.to_numpy()\n",
    "data_cat_npy = data_cat.to_numpy()\n",
    "data_sdesc_kw_npy = data_sdesc_kw.to_numpy()\n",
    "data_ldesc_kw_npy = data_ldesc_kw.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['',\n",
       "       'cloud course provides ceo president high level picture computing technology learner explore consider started adoption journey',\n",
       "       'aws mainframe service modernization help migration migrate modernize application amazon web managed runtime environment main pattern automated refactor replatform provides tool resource plan implement',\n",
       "       ...,\n",
       "       'design use designer focused fundamental course python application world increasingly impacted algorithm learn create computing program narrowly computer automation simple drafting modeling task instead explore extraordinary potential digitalization hold culture practice structured series problem code term rule syntax end know rhino script importantly lens geometrically lesson exercise',\n",
       "       'data big hadoop process course novice programmer business people like understand core tool wrangle analyze prior experience opportunity walk hand example spark framework common industry comfortable explaining specific component basic architecture software stack execution environment assignment guided scientist apply important concept technique map reduce solve fundamental problem feel empowered conversation analysis',\n",
       "       'learning machine able course hand case house data wonder tell need deeper understanding core way improve business want converse specialist regression classification deep recommender system experience series practical study end studied predict price based level feature analyze sentiment user review retrieve document interest recommend product search image practice use apply method wide range domain'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ldesc_kw_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['computer science cloud aws cloud computing',\n",
       "       'computer science cloud aws cloud computing',\n",
       "       'computer science cloud aws cloud computing', ...,\n",
       "       'computer programming python programming statistical programming theoretical computer science computational thinking data management data structure programming principle',\n",
       "       'data architecture data warehousing database application database distributed computing architecture apache python programming data structure big data computer architecture data management',\n",
       "       'linear algebra data mining machine learning dimensionality reduction feature engineering machine learning algorithm statistical machine learning applied machine learning deep learning general statistic natural language processing statistical analysis python programming computer vision regression statistical test statistical visualization basic descriptive statistic correlation dependence data analysis estimation forecasting algorithm computer programming probability statistic statistical programming theoretical computer science'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cat_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20475,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all text to create bag-of-words for each course\n",
    "data_bow = []\n",
    "\n",
    "for i in range(len(data_name)):\n",
    "    data_bow.append(' '.join((data_name_npy[i], data_cat_npy[i], data_sdesc_kw_npy[i], data_ldesc_kw_npy[i])).strip())\n",
    "\n",
    "data_bow = np.array(data_bow)\n",
    "data_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aws certified solution architect associate saa c02 cert prep 4 compute service amazon web service aws service aws deep dive compute amazon web preparation 2020 certified solution architect associate saa c02 exam service aws deep dive compute amazon web preparation 2020 certified solution architect associate saa c02 exam'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bow[4544]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v) TfIdf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit_transform BoW to Tfidf Sparse Matrix\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "data_tfidf = tfidf.fit_transform(data_bow)\n",
    "\n",
    "# Save Tfidf Vectorizer to file\n",
    "folderpath = 'Feature Map/'\n",
    "filename = 'tfidf_vectorizer'\n",
    "filepath = folderpath + filename + '.pickle'\n",
    "file = open(filepath, 'wb')\n",
    "pickle.dump(tfidf, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "file.close()\n",
    "\n",
    "# Save Tfidf Sparse Matrix to file\n",
    "\n",
    "folderpath = 'Feature Map/'\n",
    "filename = 'tfidf_data'\n",
    "filepath = folderpath + filename + '.pickle'\n",
    "file = open(filepath, 'wb')\n",
    "pickle.dump(data_tfidf, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20475, 19133)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19133)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for checking\n",
    "folderpath = 'Feature Map/'\n",
    "filename = 'tfidf_data'\n",
    "filepath = folderpath + filename + '.pickle'\n",
    "file = open(filepath, 'rb')\n",
    "data_tfidf = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "folderpath = 'Feature Map/'\n",
    "filename = 'tfidf_vectorizer'\n",
    "filepath = folderpath + filename + '.pickle'\n",
    "file = open(filepath, 'rb')\n",
    "tfidf = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction for Categorical Data\n",
    "### i) Extract Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rawdata_diff = rawdata['difficulty']\n",
    "rawdata_dur = rawdata['duration']\n",
    "rawdata_free = rawdata['free_option']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii ) One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = pd.get_dummies(rawdata_diff)\n",
    "data_dur = pd.get_dummies(rawdata_dur)\n",
    "data_free = pd.get_dummies(rawdata_free, drop_first=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Combine Data to form Catagorical Data Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20475, 8)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_cat = np.hstack((data_dur, data_diff, data_free))\n",
    "data_cat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv) Function to Encode Categorical Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_input(cat_input):\n",
    "    cat_onehot = np.zeros(6)\n",
    "    if cat_input[0] > 0: # 0 - No preference, 1 - Short, 2 - Medium, 3 - Long\n",
    "        cat_onehot[cat_input[0] - 1] = 1\n",
    "    if cat_input[1] > 0: # 0 - No preference, 1 - Introductory, 2 - Intermediate, 3 - Advanced\n",
    "        cat_onehot[cat_input[1] + 2] = 1\n",
    "    return cat_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "cat_input = [1,3] # difficulty = Medium, duration = Advanced\n",
    "cat_onehot = encode_input(cat_input)\n",
    "print(cat_onehot) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv) Save Categorical Feature Map\n",
    "### Save Categorical Feature Map to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20475, 8)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Categorical Feature Map to file\n",
    "\n",
    "folderpath = 'Feature Map/'\n",
    "filename = 'categorical_data'\n",
    "filepath = folderpath + filename + '.pickle'\n",
    "file = open(filepath, 'wb')\n",
    "pickle.dump(data_cat, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "file.close()\n",
    "\n",
    "data_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Recommendation Inference\n",
    "## i) Similarity Calculation\n",
    "### Compute Similarity on the condition that each column feature is not 0: (0 - no preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cond_sim(input_vec, data_vec):\n",
    "    input_diff = input_vec[:, :3]\n",
    "    input_durr = input_vec[:, 3:6]\n",
    "    input_free = input_vec[:, 6:]\n",
    "    data_diff  = data_vec[:, :3]\n",
    "    data_durr  = data_vec[:, 3:6]\n",
    "    data_free  = data_vec[:, 6:]\n",
    "    if (input_diff.sum() + input_durr.sum()) == 0:\n",
    "        input_slice = input_free\n",
    "        data_slice  = data_free\n",
    "    elif input_diff.sum() == 0:\n",
    "        input_slice = np.hstack((input_durr, input_free))\n",
    "        data_slice  = np.hstack((data_durr, data_free))\n",
    "    elif input_durr.sum() == 0:\n",
    "        input_slice = np.hstack((input_diff, input_free))\n",
    "        data_slice  = np.hstack((data_diff, data_free))\n",
    "    else:\n",
    "        input_slice = input_vec\n",
    "        data_slice  = data_vec\n",
    "    sim = cosine_similarity(input_slice, data_slice).ravel()\n",
    "    return sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii) Ranking Optimization for Single Group\n",
    "\n",
    "def ranking(mask, text_sim, cat_sim, rating):\n",
    "\n",
    "    target_idx = np.arange(text_sim.shape[0])[mask]\n",
    "    target_text_sim = text_sim[mask]\n",
    "    target_cat_sim = cat_sim[mask]\n",
    "    target_rating = rating[mask]\n",
    "    \n",
    "    target_scores = sorted(np.unique(target_cat_sim), reverse=True)\n",
    "    \n",
    "    rec_idx = np.array([], dtype=int)\n",
    "    rec_sim = np.array([])\n",
    "    \n",
    "    for score in target_scores:\n",
    "        group_mask = (target_cat_sim == score)\n",
    "        group_idx = target_idx[group_mask]\n",
    "        group_text_sim = target_text_sim[group_mask]\n",
    "        group_rating = target_rating[group_mask]\n",
    "        group_sort_idx = np.argsort(group_rating)[::-1]\n",
    "        rec_idx = np.append(rec_idx, group_idx[group_sort_idx])\n",
    "        rec_sim = np.append(rec_sim, group_text_sim[group_sort_idx])\n",
    "    \n",
    "    return rec_sim, rec_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iii) Recommendation Function\n",
    "def cond_sim(input_vec, data_vec):\n",
    "    input_durr = input_vec[:, :3]\n",
    "    input_diff = input_vec[:, 3:]\n",
    "    data_durr  = data_vec[:, :3]\n",
    "    data_diff  = data_vec[:, 3:]\n",
    "    if (input_durr.sum() + input_diff.sum()) == 0:\n",
    "        sim = np.ones(data_vec.shape[0])\n",
    "    elif input_durr.sum() == 0:\n",
    "        sim = cosine_similarity(input_diff, data_diff).ravel()\n",
    "    elif input_diff.sum() == 0:\n",
    "        sim = cosine_similarity(input_durr, data_durr).ravel()\n",
    "    else:\n",
    "        sim = cosine_similarity(input_vec, data_vec).ravel()\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend(inputs, thres, nmin):\n",
    "    text_ipt = inputs[0]\n",
    "    text_proc = text_preprocess(text_ipt)\n",
    "    text_tfidf = tfidf.transform([text_proc])\n",
    "    text_sim = cosine_similarity(text_tfidf, data_tfidf).ravel()\n",
    "\n",
    "    cat_ipt  = inputs[1:3]\n",
    "    cat_onehot = np.array([encode_input(cat_ipt)])\n",
    "    cat_sim = cond_sim(cat_onehot, data_cat[:, :-1])\n",
    "    \n",
    "    ind = inputs[-1]\n",
    "    \n",
    "    thres_mask = (text_sim > thres)\n",
    "    \n",
    "    if ind == 1:\n",
    "        free_mask = ((rawdata_free.to_numpy() == 1) * thres_mask) == 1\n",
    "    else:\n",
    "        free_mask = (np.ones(data_tfidf.shape[0]) * thres_mask) == 1\n",
    "    \n",
    "    paid_mask = ((np.ones(data_tfidf.shape[0]) * thres_mask) - free_mask) == 1\n",
    "        \n",
    "    print('thresss ' ,thres_mask.sum())\n",
    "    print(free_mask.sum())\n",
    "    print(paid_mask.sum())\n",
    "    \n",
    "    rec_sim, rec_idx = ranking(free_mask, text_sim, cat_sim, rawdata_rating.to_numpy())\n",
    "    \n",
    "    if (free_mask.sum() < nmin) and (paid_mask.sum() > 0):\n",
    "        paid_sim, paid_idx = ranking(paid_mask, text_sim, cat_sim, rawdata_rating.to_numpy())\n",
    "        rec_sim = np.append(rec_sim, paid_sim)\n",
    "        rec_idx = np.append(rec_idx, paid_idx)\n",
    "\n",
    "    return rec_sim, rec_idx, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresss  53\n",
      "1\n",
      "52\n",
      "1\n",
      "(53,)\n",
      "34.61858326960863\n",
      "START =================================================================================\n",
      "[0.6636283  0.59648901 0.53929666 0.73335361 0.51101915 0.76198431\n",
      " 0.59837496 0.68921725 0.54261274 0.55352903 0.66469272 0.58842388\n",
      " 0.59644371 0.81715702 0.54933452 0.56768844 0.72936715 0.52779777\n",
      " 0.86665954 0.5827612 ]\n",
      "[ 2577  6870  7004 16111 13955 16762  3586 11857  3974  4932 12971 16751\n",
      " 13031 11888  6270 12850 12455 14708  6681 15055]\n",
      "[0 0 1 0 0 1 0 2 0 0 1 0 1 0 1 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0]\n",
      "[0.23490543 1.06380897 1.06380897 1.06380897 1.04476499 1.04476499\n",
      " 1.04476499 1.04476499 1.04476499 1.04476499 1.04476499 0.90614983\n",
      " 0.90614983 0.90614983 0.90614983 0.90614983 0.74815619 0.62663377\n",
      " 0.62663377 0.62663377]\n",
      "['Data Structures - Full Course Using C and C++'\n",
      " 'Learning Data Structures and Algorithms'\n",
      " 'Algorithms and Data Structures in Java - Part II'\n",
      " 'Algorithms and Data Structures in Javascript (2020)'\n",
      " 'Data Structures and Algorithms in java'\n",
      " 'Data Structures in JavaScript: Master The Fundamentals'\n",
      " 'Java: Data Structures'\n",
      " 'Mastering Data Structures & Algorithms using C and C++'\n",
      " 'Introduction to Data Structures & Algorithms in Java'\n",
      " 'Java: Data Structures' 'Data Structures & Algorithms Essentials (2021)'\n",
      " 'Master Data Structures for Optimal Solutions in Python'\n",
      " 'Java Data Structures and Algorithms Masterclass'\n",
      " 'Easy to Advanced Data Structures'\n",
      " 'Data Structures in Java - Part I (+INTERVIEW QUESTIONS)'\n",
      " 'Fundamental Data Structures & Algorithms using C language.'\n",
      " 'Data Structures and Algorithms: In-Depth using Python'\n",
      " 'Advanced Data Structures and Algorithms in Java (Graph/Tree)'\n",
      " 'Python Data Structures A to Z'\n",
      " 'Advanced Data Structures & Algorithms in Java: Linked-List']\n",
      "['https://www.youtube.com/watch?v=B31LgI4Y4DQ'\n",
      " 'https://www.udemy.com/course/learning-data-structures-and-algorithms/'\n",
      " 'https://www.udemy.com/course/algorithms-and-data-structures-in-java-part-ii/'\n",
      " 'https://www.udemy.com/course/algorithms-and-data-structures-in-javascript/'\n",
      " 'https://www.udemy.com/course/data-structures-and-algorithms-using-java/'\n",
      " 'https://www.udemy.com/course/javascript-datastructures/'\n",
      " 'https://www.linkedin.com/learning/java-data-structures-14403471?clickid=z0z1d5QCFxyNRVVTAwVTuXn7UkAR-O0wxxCz2Y0&mcid=6851962469594763264&src=aff-ref&irgwc=1&trk=aff-ir_progid%2E8005_partid%2E259799_sid%2E_adid%2E647232'\n",
      " 'https://www.udemy.com/course/datastructurescncpp/'\n",
      " 'https://www.linkedin.com/learning/introduction-to-data-structures-algorithms-in-java?src=aff-ref&trk=aff-ir_progid.8005_partid.259799_sid._adid.647232&clickid=z0z1d5QCFxyNRVVTAwVTuXn7UkAR-9WMxxCz2Y0&mcid=6851962469594763264&irgwc=1'\n",
      " 'https://www.linkedin.com/learning/java-data-structures-14403471?src=aff-ref&trk=aff-ir_progid.8005_partid.259799_sid._adid.647232&clickid=QL-XgUQpbxyNWvP14g3642QWUkAW2718xxCwwk0&mcid=6851962469594763264&irgwc=1'\n",
      " 'https://www.udemy.com/course/cpp-data-structures-algorithms-prateek-narang/'\n",
      " 'https://www.udemy.com/course/learn-linked-lists-stacks-and-queues-in-python/'\n",
      " 'https://www.udemy.com/course/java-data-structures-and-algorithms-masterclass/'\n",
      " 'https://www.udemy.com/course/introduction-to-data-structures/'\n",
      " 'https://www.udemy.com/course/algorithms-and-data-structures/'\n",
      " 'https://www.udemy.com/course/data-structures-stack-queue-linkedlist/'\n",
      " 'https://www.udemy.com/course/learning-data-structures-algorithms-in-python-from-scratch/'\n",
      " 'https://www.udemy.com/course/data-structures-and-algorithms-in-java-2/'\n",
      " 'https://www.udemy.com/course/python-data-structures-a-to-z/'\n",
      " 'https://www.udemy.com/course/advanced-data-structures-and-algorithms-linked-lists/']\n",
      "END ===================================================================================\n",
      "[0.62019945 0.61341232 0.5337412  0.6348833  0.73040554 0.71748943\n",
      " 0.6187997  0.66958481 0.55298287 0.71008687 0.60175518 0.6831114\n",
      " 0.77488965 0.5361332  0.71681254 0.55344514 0.752181   0.67672233\n",
      " 0.69379882 0.87257072]\n",
      "[11728 14847 17185 12863 15250  7849  7522  7342 14861 12498 16334 18456\n",
      "  9792 18896 15180  1081  7892 14081 11041 19013]\n",
      "[0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 0 0 0 0 0]\n",
      "['Algorithms and Data Structures - Part 2'\n",
      " 'Data Structures and Algorithms using c++'\n",
      " 'Data Structures And Algorithms In PHP'\n",
      " 'Data Structures and Algorithms In Python'\n",
      " 'Data Structures using Javascript'\n",
      " 'Data Structure  Using C Programming With Hands On Project'\n",
      " 'Data Structures and Algorithms in C for Beginners'\n",
      " 'Data Structures in Python'\n",
      " 'Crash Course on C++ Standard Template Library (STL)'\n",
      " 'Data Structures and Algorithms In C'\n",
      " 'Data Structures & Algorithms - Python'\n",
      " 'Mastering Data Structure Using C' 'Data Structure - Part 2'\n",
      " 'C# Data Structures and Algorithms' 'Data Structures in JavaScript'\n",
      " 'Data Structures and Algorithms using Java Internship Program'\n",
      " \"Learn Data Structure Using 'C Programming Language\"\n",
      " 'Algorithms and Data Structures in C++ (2020)'\n",
      " 'Data Structure and Algorithms in Java 8 and above'\n",
      " 'Data Structures in C++']\n",
      "TIME ==================================================================================\n",
      "0.03313183784484863\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rawdata_rating = rawdata['popularity_index']\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "ainput = ['data structures', 0, 0, 1]\n",
    "\n",
    "a_sim, a_idx, a_ind = recommend(ainput, 0.5, 30)\n",
    "print(a_ind)\n",
    "print(a_sim.shape)\n",
    "print(a_sim.sum())\n",
    "# print((a_sim>(a_sim.max()-0.1)).sum())\n",
    "# print(((a_sim>(a_sim.max()-0.1)).sum())/a_sim.shape[0])\n",
    "print('START =================================================================================')\n",
    "print(a_sim[:20])\n",
    "print(a_idx[:20]+1)\n",
    "print(np.array(rawdata['duration'])[a_idx][:20])\n",
    "print(np.array(rawdata['difficulty'])[a_idx][:20])\n",
    "print(np.array(rawdata['popularity_index'])[a_idx][:20])\n",
    "print(np.array(rawdata['title'])[a_idx][:20])\n",
    "print(np.array(rawdata['url'])[a_idx][:20])\n",
    "\n",
    "print('END ===================================================================================')\n",
    "print(a_sim[-20:])\n",
    "print(a_idx[-20:]+1)\n",
    "print(np.array(rawdata['duration'])[a_idx][-20:])\n",
    "print(np.array(rawdata['difficulty'])[a_idx][-20:])\n",
    "print(np.array(rawdata['title'])[a_idx][-20:])\n",
    "print('TIME ==================================================================================')\n",
    "print(time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
